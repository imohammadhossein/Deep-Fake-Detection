{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13190,
     "status": "ok",
     "timestamp": 1585349217308,
     "user": {
      "displayName": "M. Hosein",
      "photoUrl": "",
      "userId": "09091042606436009167"
     },
     "user_tz": -270
    },
    "id": "p5QMM0OjvjN8",
    "outputId": "7ea64225-4492-47b1-e3c0-57531e9e18b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 149553 images belonging to 2 classes.\n",
      "Found 18691 images belonging to 2 classes.\n",
      "Found 18705 images belonging to 2 classes.\n",
      "{'FAKE': 0, 'REAL': 1}\n"
     ]
    }
   ],
   "source": [
    "input_shape = (299, 299, 3)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "trainPath = os.path.sep.join(['dataset/dfdc' ,\"training\"])\n",
    "valPath = os.path.sep.join(['dataset/dfdc' ,\"validation\"])\n",
    "testPath = os.path.sep.join(['dataset/dfdc', \"evaluation\"])\n",
    "\n",
    "# determine the total number of image paths in training, validation,\n",
    "# and testing directories\n",
    "totalTrain = len(list(paths.list_images(trainPath)))\n",
    "totalVal = len(list(paths.list_images(valPath)))\n",
    "totalTest = len(list(paths.list_images(testPath)))\n",
    "\n",
    "# initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "\trotation_range=3,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.1,\n",
    "\theight_shift_range=0.1,\n",
    "\tshear_range=0.05,\n",
    "\thorizontal_flip=False,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation/testing data augmentation object (which\n",
    "# we'll be adding mean subtraction to)\n",
    "valAug = ImageDataGenerator()\n",
    "\n",
    "# define the ImageNet mean subtraction (in RGB order) and set the\n",
    "# the mean subtraction value for each of the data augmentation\n",
    "# objects\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean\n",
    "\n",
    "# def to prevent from bad input images\n",
    "def my_gen(gen):\n",
    "  i = 0\n",
    "  while True:\n",
    "    try:\n",
    "        data, labels = next(gen)\n",
    "        yield data, labels\n",
    "    except:\n",
    "        print(i)\n",
    "        i += 1\n",
    "        pass\n",
    "\n",
    "\n",
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\ttrainPath,\n",
    "\tclass_mode=\"binary\",\n",
    "\ttarget_size=(299, 299),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=BATCH_SIZE)\n",
    "\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tvalPath,\n",
    "\tclass_mode=\"binary\",\n",
    "\ttarget_size=(299, 299),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BATCH_SIZE)\n",
    "\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "\ttestPath,\n",
    "\tclass_mode=\"binary\",\n",
    "\ttarget_size=(299, 299),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BATCH_SIZE)\n",
    "\n",
    "labels = (trainGen.class_indices)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34415,
     "status": "ok",
     "timestamp": 1585349314619,
     "user": {
      "displayName": "M. Hosein",
      "photoUrl": "",
      "userId": "09091042606436009167"
     },
     "user_tz": -270
    },
    "id": "wvRD8alGwH6b",
    "outputId": "80fae6bc-4422-42ec-c08a-5cc3849ab987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_resnet_v2 (Model)  (None, 8, 8, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1537      \n",
      "=================================================================\n",
      "Total params: 54,338,273\n",
      "Trainable params: 54,277,729\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# googleNet_model = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "\n",
    "hidden_dim = 256\n",
    "hidden_dim1 = 128\n",
    "googleNet_model = InceptionResNetV2( include_top=False, weights='imagenet', input_shape=(299, 299, 3))\n",
    "\n",
    "# version 1\n",
    "last_layer = googleNet_model.get_layer('conv_7b_ac').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
    "x = Dense(hidden_dim1, activation='relu', name='fc7')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "out = Dense(1, activation='sigmoid', name='fc8')(x)\n",
    "custom_googleNet_model = Model(googleNet_model.input, out)\n",
    "\n",
    "for layer in custom_googleNet_model.layers:\n",
    "\tlayer.trainable = False\n",
    "for layer in custom_googleNet_model.layers[782:]:\n",
    "\tlayer.trainable = True\n",
    "\n",
    "#version 2\n",
    "googleNet_model.trainable = True\n",
    "custom_googleNet_model = Sequential()\n",
    "custom_googleNet_model.add(googleNet_model)\n",
    "custom_googleNet_model.add(GlobalAveragePooling2D())\n",
    "custom_googleNet_model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "custom_googleNet_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "custom_googleNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rrZTANSyA6g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO7bEyp5G3unYGQYeUlVSA+",
   "collapsed_sections": [],
   "mount_file_id": "1nxP-dfOHQmFZNT05s0RjtRefhlTJTMqe",
   "name": "ResWhat",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
